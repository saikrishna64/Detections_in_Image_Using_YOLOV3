{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9079df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "threshold=0.6\n",
    "image_size=320\n",
    "NMS_threshold=0.7\n",
    "\n",
    "def best_outcome(detected_data):\n",
    "    bounding_box = []\n",
    "    conf = []\n",
    "    classes = []\n",
    "    \n",
    "    for i in detected_data:\n",
    "        for j in i:\n",
    "            values = j[5:]\n",
    "            class_ids = np.argmax(values)\n",
    "            confidence = values[class_ids]\n",
    "            if confidence>threshold:\n",
    "                w , h =int(j[2]*image_size), int(j[3]*image_size)\n",
    "                x , y =int(j[0]*image_size-w/2), int(j[1]*image_size-h/2)\n",
    "                bounding_box.append([x,y,w,h])\n",
    "                conf.append(confidence)\n",
    "                classes.append(class_ids)\n",
    "                \n",
    "    predicted_box=cv2.dnn.NMSBoxes(bounding_box, conf, threshold, NMS_threshold)\n",
    "    return predicted_box, bounding_box, conf, classes\n",
    "\n",
    "def final_detection(final_box, bounding, prob, classes, height, width):\n",
    "    for i in final_box.flatten():\n",
    "        k=bounding[i]\n",
    "        x, y, w, h = k\n",
    "        \n",
    "        x=int(x*width)\n",
    "        y=int(y*height)\n",
    "        w=int(w*width)\n",
    "        h=int(h*height)\n",
    "        cv2.rectangle(image, (x,y), (x+w,y+h), (0,0,255), 2)\n",
    "        font=cv2.FONT_HERSHEY_COMPLEX\n",
    "        label=class_names[classes[0]]\n",
    "        c1=prob[i]\n",
    "        cc=round(c1,2)\n",
    "        text= str(label)+':'+str(cc)+'%'\n",
    "        cv2.putText(image, text, (x,y-3), font, 0.5, (255,0,0), 1)\n",
    "    \n",
    "\n",
    "class_names=[]\n",
    "\n",
    "sol=open('./class_names', 'r')\n",
    "for i in sol.readlines():\n",
    "    class_names.append(i.strip())\n",
    "\n",
    "image=cv2.imread('./test_2.jpg')\n",
    "#plt.imshow(image[:,:,::-1])\n",
    "\n",
    "#loading cfg and weights file:\n",
    "original_width = image.shape[1]\n",
    "original_height = image.shape[0]\n",
    "\n",
    "nn=cv2.dnn.readNetFromDarknet('./yolov3 (1).cfg' , './yolov3.weights')\n",
    "#print(nn.getLayerNames()) #complete architecture\n",
    "#print(nn.getUnconnectedOutLayers()) #which line yolo detections are going\n",
    "#print(nn.getUnconnectedOutLayersNames()) #layer names (detections in layers)\n",
    "\n",
    "#Getting Image ready for Yolo detection\n",
    "\n",
    "image_yolo = cv2.dnn.blobFromImage(image, 1 / 255 , (320,320), True, crop=False )\n",
    "#image_yolo.shape\n",
    "\n",
    "#input image to yolo\n",
    "nn.setInput(image_yolo)\n",
    "c=nn.getLayerNames()\n",
    "#print([c[i-1] for i in nn.getUnconnectedOutLayers()])\n",
    "outputs = [c[i-1] for i in nn.getUnconnectedOutLayers()]\n",
    "detected_data=nn.forward(outputs)\n",
    "#detected_data[0].shape\n",
    "predicted_box_1 , bounding_box_1 , conf_1 , classes_1 = best_outcome(detected_data)\n",
    "final_detection(predicted_box_1, bounding_box_1, conf_1, classes_1, original_height/320, original_width/320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8137f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image' , image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bc54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
